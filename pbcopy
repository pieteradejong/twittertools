diff --git a/README.md b/README.md
index 29d3343..865c342 100644
--- a/README.md
+++ b/README.md
@@ -2,23 +2,165 @@
 
 [![twittertools](https://github.com/pieteradejong/twittertools/actions/workflows/ci.yml/badge.svg?branch=main)](https://github.com/pieteradejong/twittertools/actions/workflows/ci.yml)
 
-## Goal: v0.1 Milestone
-~~* :white_check_mark: make successful Twitter API call~~
-
-## Todos
-* [DONE] load all tweets from archive download
-* [DONE] use open source "`zero-shot-classification`" classifier to detect given themes
-* [DONE] save classifications to sqliteDB (they are expensive, deterministic, and I want to work with `sqlite`)
-  * steps for performing an expensive operation like classification:
-    * 1) before starting, load from db table all tweet_id's that already have a classification for the given topic
-    * 2) classify all other tweets and append to in-memory list
-    * 3) when all done, insert added classifications to db
-* [TODO] fetch own tweets with zero likes or zero replies or zero retweets
-  * [TODO] tweet['favorite_count'] for "likes"
-  * [TODO] tweet['retweet_count'] for RT count
-* [TODO] create `dataclass Tweet`
-* [TODO] `classify_tweets` should take classifier as a parameter instead of hardcoded
+A full-stack application for analyzing and managing Twitter/X data, featuring a Python FastAPI backend and React frontend.
 
+## Features
+
+* Twitter API Integration
+  * Fetch and analyze Twitter likes and tweets
+  * User authentication and profile management
+  * Rate limit handling
+* Data Management
+  * Local storage of Twitter data
+  * Tweet classification and analysis
+  * User engagement metrics
+* Modern Interface
+  * RESTful API with OpenAPI documentation
+  * CLI interface for quick data access
+  * React frontend for data visualization
+  * List management and recommendations
+
+## Prerequisites
+
+* Python 3.8 or higher
+* Node.js 16 or higher and npm
+* Twitter/X API credentials:
+  * API Key
+  * API Secret
+  * Access Token
+  * Access Token Secret
+  * Bearer Token
+
+## Quick Start
+
+1. Clone the repository:
+```bash
+git clone https://github.com/pieteradejong/twittertools.git
+cd twittertools
+```
+
+2. Run the initialization script:
+```bash
+./init.sh
+```
+
+3. Fill in your Twitter API credentials in the `.env` file
+
+4. Start the development servers:
+```bash
+./run.sh
+```
+
+The application will be available at:
+* Frontend: http://localhost:5173
+* Backend API: http://localhost:8000
+* API Documentation: http://localhost:8000/docs
+
+## Development
+
+### Project Structure
+```
+twittertools/
+├── src/                    # Backend Python code
+│   ├── main.py            # FastAPI application and CLI
+│   ├── config.py          # Configuration management
+│   └── __pycache__/       # Python cache files
+├── frontend/              # React frontend (Vite)
+│   ├── src/              # React source code
+│   └── .env              # Frontend environment variables
+├── data/                 # Local data storage
+│   └── twittertools.db   # SQLite database
+├── .env                  # Backend environment variables
+├── init.sh               # Setup script
+└── run.sh                # Development server script
+```
+
+### Backend Development
+The backend is built with FastAPI and provides:
+
+#### API Endpoints
+* `GET /health` - Health check endpoint
+* `GET /api/me` - Get authenticated user info
+* `GET /api/likes` - Get recent likes (with optional count parameter)
+
+#### Features
+* Twitter API integration with OAuth and Bearer token support
+* Data storage and analysis
+* RESTful API with OpenAPI documentation
+* Tweet classification (coming soon)
+* CLI interface for quick data access
+
+To run the backend server separately:
+```bash
+source env/bin/activate
+python -m uvicorn src.main:app --reload
+```
+
+To use the CLI interface:
+```bash
+source env/bin/activate
+python -m src.main --number 10  # Fetch 10 recent likes
+```
+
+> **Note:** Always run the CLI as a module (with `-m src.main`) from the project root to ensure imports work for both CLI and API modes.
+
+### Frontend Development
+The frontend is built with:
+* React + TypeScript
+* Vite for development
+* Mantine UI components
+* React Query for data fetching
+
+To run the frontend development server separately:
+```bash
+cd frontend
+npm run dev
+```
+
+## API Documentation
+Once the backend server is running, visit:
+* Swagger UI: http://localhost:8000/docs
+* ReDoc: http://localhost:8000/redoc
+
+The API documentation includes:
+* Interactive API testing
+* Request/response schemas
+* Authentication requirements
+* Example requests
+
+## Current Status
+
+### Completed Features
+* [x] Twitter API integration
+* [x] Basic API endpoints
+* [x] CLI interface
+* [x] Configuration management
+* [x] Health check endpoint
+* [x] User authentication
+* [x] Likes fetching
+
+### In Progress
+* [ ] Frontend implementation
+* [ ] Tweet classification
+* [ ] Data visualization
+* [ ] List management
+
+### Planned Features
+* [ ] User engagement metrics
+* [ ] Tweet analysis
+* [ ] List recommendations
+* [ ] Block/unblock management
+* [ ] Follow/unfollow tracking
+
+## Contributing
+1. Fork the repository
+2. Create a feature branch
+3. Commit your changes
+4. Push to the branch
+5. Create a Pull Request
+
+## License
+[Add your license here]
 
 [DEPRECATED] ~~## Functional requirements~~
 * show who I blocked and when, plus reminders to potentially unblock
diff --git a/init.sh b/init.sh
index 41876e9..3b8354a 100755
--- a/init.sh
+++ b/init.sh
@@ -1,19 +1,89 @@
 #!/bin/bash
 
-# USAGE: after running init.sh, don't forget to activate virtualenv: 'source venv/bin/activate'
+# Colors for output
+GREEN='\033[0;32m'
+YELLOW='\033[1;33m'
+RED='\033[0;31m'
+NC='\033[0m' # No Color
 
-# create Python virtual environment if it doesn't exist
-if [ ! -d "venv" ]; then
-    python3 -m venv venv
+echo -e "${GREEN}Initializing Twitter Tools...${NC}"
+
+# Check if Python 3 is installed
+if ! command -v python3 &> /dev/null; then
+    echo -e "${RED}Python 3 is required but not installed. Please install Python 3 first.${NC}"
+    exit 1
+fi
+
+# Check if Node.js and npm are installed
+if ! command -v node &> /dev/null || ! command -v npm &> /dev/null; then
+    echo -e "${RED}Node.js and npm are required but not installed. Please install them first.${NC}"
+    exit 1
 fi
 
-# activate virtual environment
-source venv/bin/activate
+# Create virtual environment if it doesn't exist
+if [ ! -d "env" ]; then
+    echo -e "${YELLOW}Creating virtual environment...${NC}"
+    python3 -m venv env
+    echo -e "${GREEN}Virtual environment created.${NC}"
+fi
 
-# install dependencies
-pip install -r requirements.txt
+# Activate virtual environment
+echo -e "${YELLOW}Activating virtual environment...${NC}"
+source env/bin/activate
 
-# Additional setup steps can be added here
+# Install/upgrade pip and requirements
+echo -e "${YELLOW}Upgrading pip and installing requirements...${NC}"
+pip install --upgrade pip
+if [ -f "requirements.txt" ]; then
+    pip install -r requirements.txt
+else
+    echo -e "${RED}requirements.txt not found. Please create one with your dependencies.${NC}"
+    exit 1
+fi
+
+# Create .env file if it doesn't exist
+if [ ! -f ".env" ]; then
+    echo -e "${YELLOW}Creating .env template file...${NC}"
+    python3 -c "from config import create_env_template; create_env_template()"
+    echo -e "${GREEN}.env template created. Please fill in your Twitter API credentials.${NC}"
+fi
+
+# Create data directory for local storage
+if [ ! -d "data" ]; then
+    echo -e "${YELLOW}Creating data directory for local storage...${NC}"
+    mkdir -p data
+    echo -e "${GREEN}Data directory created.${NC}"
+fi
+
+# Set up frontend if it doesn't exist
+if [ ! -d "frontend" ]; then
+    echo -e "${YELLOW}Setting up React frontend with Vite...${NC}"
+    npm create vite@latest frontend -- --template react-ts
+    cd frontend
+    npm install
+    # Add additional frontend dependencies
+    npm install @tanstack/react-query axios @mantine/core @mantine/hooks @emotion/react
+    cd ..
+    echo -e "${GREEN}Frontend setup complete.${NC}"
+fi
+
+# Create frontend .env file if it doesn't exist
+if [ ! -f "frontend/.env" ]; then
+    echo -e "${YELLOW}Creating frontend .env file...${NC}"
+    cat > frontend/.env << EOL
+VITE_API_URL=http://localhost:8000
+EOL
+    echo -e "${GREEN}Frontend .env file created.${NC}"
+fi
 
-echo
-echo -e "\033[0;32mInitialization complete! Use 'source venv/bin/activate' to activate the virtual environment.\033[0m"
+echo -e "${GREEN}Initialization complete!${NC}"
+echo -e "${YELLOW}Next steps:${NC}"
+echo "1. Fill in your Twitter API credentials in the .env file"
+echo "2. Activate the virtual environment: source env/bin/activate"
+echo "3. Start the development servers: ./run.sh"
+echo -e "\n${YELLOW}Project structure:${NC}"
+echo "├── src/              # Backend Python code"
+echo "├── frontend/         # React frontend"
+echo "├── data/            # Local data storage"
+echo "├── .env             # Backend environment variables"
+echo "└── frontend/.env    # Frontend environment variables"
diff --git a/requirements.txt b/requirements.txt
index 6552c02..40b9699 100644
--- a/requirements.txt
+++ b/requirements.txt
@@ -1,6 +1,24 @@
+# Core dependencies
+tweepy>=4.14.0
+rich>=13.6.0
+python-dotenv>=1.0.0
+fastapi>=0.104.0
+uvicorn>=0.24.0
+sqlalchemy>=2.0.23
+pydantic>=2.4.2
+
+# Development tools
 black==23.3.0
 ruff==0.3.3
 pytest==7.2.0
-python-dotenv==1.0.1
-transformers==4.38.2
-torch==2.2.1
\ No newline at end of file
+
+# Optional: Classification features
+# transformers>=4.35.0  # Uncomment if using zero-shot classification
+# torch>=2.1.0         # Uncomment if using zero-shot classification
+
+# Optional: Additional features
+# numpy>=1.24.0        # Uncomment if needed for data analysis
+# pandas>=2.1.0        # Uncomment if needed for data analysis
+# python-multipart>=0.0.6  # Uncomment if implementing file uploads
+# aiofiles>=23.2.1     # Uncomment if implementing async file operations
+# httpx>=0.25.0        # Uncomment if implementing async HTTP requests
diff --git a/src/analysis.py b/src/analysis.py
deleted file mode 100644
index bf066b6..0000000
--- a/src/analysis.py
+++ /dev/null
@@ -1,47 +0,0 @@
-# import private
-# import tweepy
-
-
-# def get_user_follows(client: tweepy.Client, user_id: int) -> list:
-#     pass
-
-# def get_user_followers(client: tweepy.Client, user_id: int) -> list:
-#     # response = client.get_users_followers(user_id, user_fields=["profile_image_url"])
-#     response = client.get_users_followers(user_id)
-#     return response.data
-
-# def get_follow_followed_overlap():
-#     pass
-
-# def get_user_tweets(client: tweepy.Client, user_id: int) -> list:
-#     response = client.get_users_tweets(user_id, user_fields=["created_at", "description"])
-#     return response.data
-
-# def get_client_methods(client: tweepy.Client) -> list:
-#     return dir(client)
-
-# def main():
-#     print('Hello Tweepy')
-
-#     client = tweepy.Client(
-#         bearer_token=private.Bearer_Token,
-#         access_token=private.Access_Token,
-#         access_token_secret=private.Access_Token_Secret,
-#         consumer_secret=private.API_Secret_Key
-#     )
-
-#     user_tweets = get_user_tweets(client, private.TWITTER_USER_ID)
-#     for tweet in user_tweets:
-#         print(tweet.id)
-#         print(tweet.text)
-
-#     # user_followers = get_user_followers(client, private.TWITTER_USER_ID)
-#     # for f in user_followers:
-#     #     print(f)
-
-#     # client_methods = get_client_methods(client)
-#     # print(*client_methods, sep="\n")
-
-
-# if __name__ == "__main__":
-#     main()
diff --git a/src/favorites.py b/src/favorites.py
deleted file mode 100644
index eca91b3..0000000
--- a/src/favorites.py
+++ /dev/null
@@ -1,13 +0,0 @@
-# import twitter
-# import env
-
-# api = twitter.Api(
-#  consumer_key=env.config['consumer_key'],
-#  consumer_secret=env.config['consumer_secret'],
-#  access_token_key=env.config['access_token_key'],
-#  access_token_secret=env.config['access_token_secret']
-#  )
-
-
-# favorites = api.GetFavorites()
-# print [f for f in favorites]
diff --git a/src/main.py b/src/main.py
index 2ae32e5..5c8917d 100644
--- a/src/main.py
+++ b/src/main.py
@@ -1,263 +1,471 @@
 """
-Base App
+Twitter Tools - Twitter Data Analysis and Management
 
+A full-stack application for analyzing and managing Twitter/X data.
+Features both a CLI interface and a REST API.
 """
+import argparse
 import logging
-from dotenv import load_dotenv
-import json
-from transformers import pipeline
-import sqlite3
-import os
-from enum import Enum
-
-class Theme(Enum):
-    POLITICS = 'politics'
-    RELIGION = 'religion'
-    ENTERTAINMENT = 'entertainment'
-    MIAMI = 'Miami'
-    TECHNOLOGY = 'technology'
-    GEOPOLITICS = 'geopolitics'
-    EUROPE = 'Europe'
-    SPACEFLIGHT = 'spaceflight'
-
-THRESHOLD_CLASSIFICATION_DEFAULT = 0.7  # initial guess; adjust as needed
-
-def init():
-    load_dotenv()
-    logging.basicConfig(
-        level=logging.INFO,
-        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
-    )
-    logger_data = logging.getLogger('data_warnings')
-    handler = logging.FileHandler('logs/data_warnings.log')
-    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
-    handler.setFormatter(formatter)
-    logger_data.addHandler(handler)
-    logger_data.setLevel(logging.WARNING)
+from typing import List, Dict, Any, Optional
+from datetime import datetime, timedelta
+import tweepy
+from fastapi import FastAPI, HTTPException, Depends
+from fastapi.middleware.cors import CORSMiddleware
+from pydantic import BaseModel
+from rich.console import Console
+from rich.table import Table
+
+from src.config import twitter_config, app_config, create_env_template
+
+# Set up logging
+logging.basicConfig(
+    level=logging.INFO,
+    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
+)
+logger = logging.getLogger(__name__)
+
+# Initialize FastAPI app
+app = FastAPI(
+    title="Twitter Tools API",
+    description="API for analyzing and managing Twitter/X data",
+    version="0.1.0"
+)
+
+# Configure CORS
+app.add_middleware(
+    CORSMiddleware,
+    allow_origins=[app_config.frontend_url],
+    allow_credentials=True,
+    allow_methods=["*"],
+    allow_headers=["*"],
+)
+
+# Pydantic models for API
+class Tweet(BaseModel):
+    id: str
+    text: str
+    created_at: datetime
+    metrics: Dict[str, int]
+
+class UserInfo(BaseModel):
+    username: str
+    id: str
+    name: Optional[str] = None
+
+class RateLimitInfo(BaseModel):
+    is_rate_limited: bool
+    reset_time: Optional[datetime] = None
+    wait_seconds: Optional[int] = None
+    endpoint: Optional[str] = None
+
+class AuthStatus(BaseModel):
+    is_authenticated: bool
+    username: Optional[str] = None
+    error: Optional[str] = None
+    can_fetch_data: bool = False
+    test_tweet_count: Optional[int] = None
+    rate_limit: Optional[RateLimitInfo] = None
+
+class TwitterClient:
+    """Singleton class to manage Twitter API client."""
     
-    logging.info("Initializing application")
-    logging.info("Configured logging.")
-    logging.info("Set environment variables.")
-
-    conn = sqlite3.connect("theme_classifications.db")
-    cursor = conn.cursor()
-
-    cursor.execute(
-        """
-        CREATE TABLE IF NOT EXISTS scores (
-            tweet_id TEXT PRIMARY KEY,
-            full_text TEXT NOT NULL,
-            theme TEXT NOT NULL,
-            score REAL NOT NULL
+    _instance = None
+    _client = None
+    _rate_limit_info = None
+    
+    def __new__(cls):
+        if cls._instance is None:
+            cls._instance = super(TwitterClient, cls).__new__(cls)
+            cls._instance._initialize_client()
+        return cls._instance
+    
+    def _handle_rate_limit(self, e: tweepy.TooManyRequests) -> None:
+        """Handle rate limit exceeded error."""
+        reset_time = datetime.fromtimestamp(e.response.headers.get('x-rate-limit-reset', 0))
+        wait_seconds = int((reset_time - datetime.now()).total_seconds())
+        endpoint = e.response.url.split('/')[-1]  # Get the endpoint that was rate limited
+        
+        self._rate_limit_info = RateLimitInfo(
+            is_rate_limited=True,
+            reset_time=reset_time,
+            wait_seconds=wait_seconds,
+            endpoint=endpoint
         )
-        """
-    )
-
-    cursor.execute("CREATE INDEX IF NOT EXISTS idx_tweet_id ON scores (tweet_id)")
-    # fetch already-classified's by theme: don't perform duplicate work
-    cursor.execute("CREATE INDEX IF NOT EXISTS idx_theme ON scores (theme)")
-
-    conn.commit()
-    logging.info(
-        "Initialized SQLite database and created necessary table and index(es)."
-    )
-    return conn
-
-def terminate(conn: sqlite3.Connection) -> None:
-    """
-    Clean up resources and gracefully terminate the application.
-    """
-    if conn:
-        conn.close()
-        logging.info("Database connection closed.")
-    logging.info("Application terminated.")
-
-def display_db(conn: sqlite3):
-    cursor = conn.cursor()
-
-    cursor.execute("SELECT name FROM sqlite_master WHERE type='table';")
-    tables = cursor.fetchall()
-
-    for table_name in tables:
-        table_name = table_name[0]
-        logging.info(f"Table: {table_name}")
-
-        # Retrieve column information
-        cursor.execute(f"PRAGMA table_info({table_name});")
-        columns = cursor.fetchall()
-        column_names = [column[1] for column in columns]
-        logging.info(f"Columns: {column_names}")
-
-        # Count the rows in the table
-        cursor.execute(f"SELECT COUNT(*) FROM {table_name};")
-        count = cursor.fetchone()[0]
-        logging.info(f"Row count: {count}\n")
-
-
-def fetchTweets():
-    """
-    Returns: [{
-      "tweet" : {
-        "edit_info" : {},
-        "favorite_count": int,
-        "id_str": str,
-        "retweet_count": int,
-        "full_text": str,
-        "in_reply_to_user_id_str": str,
-        ...
-        },
-    ]
-    """
-    with open("twitter-personal-archive/tweets.json", "r") as file:
-        tweets = json.load(file)
-    return tweets["tweets"]
-
-
-# def filter_are_replies(tweets: list) -> list:
-#     are_replies = []
-#     for tw in tweets:
-#         data = tw["tweet"]
-#         if data.get("in_reply_to_status_id", "") != "":
-#             are_replies.append(tw)
-
-#     return are_replies
-
-
-# def extract_replies(tweets: list):
-#     """
-#     fields relevant to replies:
-#         'in_reply_to_user_id_str',
-#         'in_reply_to_status_id_str',
-#         'in_reply_to_user_id',
-#         'in_reply_to_status_id', (most relevant bc it's the actual tweet)
-#         'in_reply_to_screen_name'
-#     """
-#     pass
-
-
-def fetch_classified_tweet_ids(conn: sqlite3, theme: str) -> set:
-    cursor = conn.cursor()
-    try:
-        cursor.execute("SELECT tweet_id FROM scores WHERE theme = ?", (theme,))
-        existing_ids = set(row[0] for row in cursor.fetchall())
-        return existing_ids
-    except sqlite3.Error as e:
-        logging.error(f"Database error: {e}")
-        return set()
-
-
-def classify_tweets(tweets: list, theme: str) -> list:
-    classifier = pipeline("zero-shot-classification", model="facebook/bart-large-mnli")
-    classified_tweets = []
-
-    logging.info(f"Classifying {len(tweets)} tweets for theme '{theme}'")
-    count = 0
-    for tw_obj in tweets:
-        count += 1
-        if count % 100 == 0:
-            logging.info(f"Classified {count} out of {len(tweets)} tweets.")
-        tweet = tw_obj.get("tweet", "")
-        if not tweet:
-            logger_data.warn('object found with no tweet')
-            continue
-        full_text = tweet.get("full_text", "")
-        tweet_id = tweet.get("id", "")
-        if not tweet_id:
-            logger_data.warn('tweet found with no id')
-            continue
-        if not full_text:
-            logger_data.warn(f'tweet has no full_text [(id{tweet_id})]')
-            continue
-        classification = classifier(full_text, theme)
-        # print(f'\033[95mClassified tweet full text {full_text} for theme {theme}: {classification}\033[0m')
-        scores_by_theme = dict(zip(classification["labels"], classification["scores"]))
-        classification_score = scores_by_theme.get(theme, 0)
-        if not classification_score:
-            logger_data.warn(f'no score found for theme {theme} after classification (tweet_id [{tweet_id}])')
-            continue
-        classified = {
-            "tweet_id": tweet_id,
-            "tweet_full_text": full_text,
-            "theme_measured": theme,
-            "classification_score": classification_score,
-        }
-        classified_tweets.append(classified)
-    return classified_tweets
-
-def insert_classified_tweets(conn: sqlite3.Connection, classified_tweets: list) -> int:
-    cursor = conn.cursor()
-    rows_affected = 0
-    for tweet in classified_tweets:
+        
+        logger.warning(f"Rate limit exceeded for {endpoint}. Reset at {reset_time}. Waiting {wait_seconds} seconds.")
+    
+    def _clear_rate_limit(self) -> None:
+        """Clear rate limit information."""
+        self._rate_limit_info = None
+    
+    def _initialize_client(self):
+        """Initialize the Twitter client with credentials."""
+        if not twitter_config.validate_credentials():
+            create_env_template()
+            raise ValueError("Twitter credentials not found. Please check your .env file.")
+        
         try:
-            cursor.execute(
-                "INSERT INTO scores (tweet_id, full_text, theme, score) VALUES (?, ?, ?, ?)",
-                (
-                    tweet["tweet_id"],
-                    tweet["tweet_full_text"],
-                    tweet["theme_measured"],
-                    tweet["classification_score"],
-                ),
+            # First try with just the bearer token
+            logger.info("Testing authentication with Bearer Token only...")
+            bearer_client = tweepy.Client(
+                bearer_token=twitter_config.get_bearer_token(),
+                wait_on_rate_limit=True,  # Enable built-in rate limit handling
+                return_type=dict  # Return dictionaries instead of objects for better control
             )
-            rows_affected += cursor.rowcount
-            logging.info(f"Successfully inserted tweet_id: {tweet['tweet_id']} into the database.")
-        except sqlite3.Error as e:
-            logging.error(f"Failed to insert tweet_id: {tweet['tweet_id']} into the database. Error: {e}")
-    conn.commit()
-    return rows_affected
-
-def classify_and_save(conn: sqlite3, tweets: list, theme: str) -> int:
-    existing_ids: set = fetch_classified_tweet_ids(conn, theme)
-    # logging.info(f"Number of existing scored tweets IDs: {len(existing_ids)}")
+            
+            # Test bearer token
+            try:
+                test_tweet = bearer_client.get_tweet(123456789)  # This will fail but we just want to test auth
+            except tweepy.NotFound:
+                logger.info("Bearer Token authentication successful!")
+            except tweepy.TooManyRequests as e:
+                self._handle_rate_limit(e)
+                raise
+            except tweepy.Unauthorized as e:
+                logger.error("Bearer Token authentication failed!")
+                logger.error("Please verify your Bearer Token in the Twitter Developer Portal")
+                raise
+            
+            # Now try with full OAuth
+            logger.info("Testing full OAuth authentication...")
+            self._client = tweepy.Client(
+                bearer_token=twitter_config.get_bearer_token(),
+                consumer_key=twitter_config.get_api_key(),
+                consumer_secret=twitter_config.get_api_secret(),
+                access_token=twitter_config.get_access_token(),
+                access_token_secret=twitter_config.get_access_token_secret(),
+                wait_on_rate_limit=True,  # Enable built-in rate limit handling
+                return_type=dict  # Return dictionaries instead of objects for better control
+            )
+            
+            # Test OAuth by getting user info
+            try:
+                me = self._client.get_me()
+                logger.info(f"OAuth authentication successful! Authenticated as: @{me['data']['username']}")
+                self._clear_rate_limit()  # Clear any rate limit info on successful auth
+            except tweepy.TooManyRequests as e:
+                self._handle_rate_limit(e)
+                raise
+            
+        except tweepy.Unauthorized as e:
+            logger.error("Authentication failed. Please check your credentials:")
+            logger.error("1. Make sure your API keys and tokens are correct")
+            logger.error("2. Verify that your Twitter Developer account is active")
+            logger.error("3. Check if your app has the required permissions")
+            logger.error("4. Verify your app's OAuth 2.0 settings in the Developer Portal")
+            logger.error(f"Error details: {str(e)}")
+            raise
+        except tweepy.TweepyException as e:
+            logger.error(f"Twitter API error: {str(e)}")
+            raise
+
+    @property
+    def rate_limit_info(self) -> Optional[RateLimitInfo]:
+        """Get current rate limit information."""
+        return self._rate_limit_info
+
+    @property
+    def client(self) -> tweepy.Client:
+        """Get the Twitter client instance."""
+        if not self._client:
+            self._initialize_client()
+        return self._client
+
+# Dependency for FastAPI endpoints
+def get_twitter_client() -> TwitterClient:
+    """Dependency to get Twitter client instance."""
+    return TwitterClient()
+
+class TwitterService:
+    """Service class for Twitter operations."""
     
-    # logging.info(f'Number of existing IDs: {len(existing_ids)}')
-    tweets_not_yet_classified = [t for t in tweets if t['tweet'].get('id', '') not in existing_ids]
-    # logging.info(f'\033[94mNumber of tweets not yet clasified: {len(tweets_not_yet_classified)}\033[0m')
-    classified_tweets: list = classify_tweets(tweets_not_yet_classified, theme)
+    def __init__(self, client: Optional[TwitterClient] = None):
+        if client is None:
+            client = TwitterClient()
+        self.client = client.client
+        self.console = Console()
     
-    rows_inserted = insert_classified_tweets(conn, classified_tweets)
-    logging.info(f'Number of classified tweets inserted into database: [{rows_inserted}]')
+    def get_recent_likes(self, count: int = 10) -> List[Dict[str, Any]]:
+        """Fetch recent likes for the authenticated user."""
+        try:
+            # Get user ID for the authenticated user
+            me = self.client.get_me()
+            user_id = me.data.id
+            
+            # Get recent likes
+            likes = self.client.get_liked_tweets(
+                user_id,
+                max_results=count,
+                tweet_fields=['created_at', 'public_metrics', 'text']
+            )
+            
+            if not likes.data:
+                logger.info("No likes found")
+                return []
+            
+            # Format the results
+            formatted_likes = []
+            for tweet in likes.data:
+                formatted_likes.append({
+                    'id': tweet.id,
+                    'text': tweet.text,
+                    'created_at': tweet.created_at,
+                    'metrics': tweet.public_metrics
+                })
+            
+            return formatted_likes
+            
+        except tweepy.Unauthorized as e:
+            logger.error("Authentication failed while fetching likes:")
+            logger.error("1. Your credentials might have expired")
+            logger.error("2. Your app might not have the 'Likes' permission")
+            logger.error(f"Error details: {str(e)}")
+            raise HTTPException(status_code=401, detail=str(e))
+        except tweepy.TweepyException as e:
+            logger.error(f"Error fetching likes: {str(e)}")
+            raise HTTPException(status_code=500, detail=str(e))
     
-    return rows_inserted
-
-# def generate_url_from_tweet_id(tweet_id):
-#     twitter_username = os.getenv('TWITTER_USERNAME')
-#     return f"https://twitter.com/{twitter_username}/status/{tweet_id}"
-
-def main():
-    conn = init()
-    tweets = fetchTweets()
-    print(f"Number of tweets: {len(tweets)}")
-
-    # section: classify by topic
-    # classify_topic(tweets)
-    # political = get_tweets_for_theme(conn, tweets, "political")
-    tweets_classified_and_inserted = classify_and_save(conn, tweets, Theme.ENTERTAINMENT.value)
-    logging.info(f'Number of tweets classified and inserted: {tweets_classified_and_inserted}')
-    # print(f"Length of political tweets: {len(political)}")
-    # print("First 5 political tweets:", political[:5])
-
-    # section: get favorites / retweets
-    # engagement = {}
-    # for t in tweets:
-    #     fav_count = int(t['tweet']['favorite_count'])
-    #     rt_count = int(t['tweet']['retweet_count'])
-    #     tw_id = t['tweet']['id_str']
-    #     if fav_count > 0 or rt_count > 0:
-    #         engagement[tw_id] = {
+    def display_likes(self, likes: List[Dict[str, Any]]) -> None:
+        """Display likes in a formatted table using Rich."""
+        if not likes:
+            self.console.print("[yellow]No likes found![/yellow]")
+            return
+        
+        table = Table(title="Recent Twitter Likes")
+        table.add_column("Date", style="cyan")
+        table.add_column("Tweet", style="green")
+        table.add_column("Likes", justify="right", style="magenta")
+        table.add_column("Retweets", justify="right", style="blue")
+        
+        for like in likes:
+            created_at = like['created_at'].strftime("%Y-%m-%d %H:%M")
+            metrics = like['metrics']
+            table.add_row(
+                created_at,
+                like['text'][:100] + "..." if len(like['text']) > 100 else like['text'],
+                str(metrics['like_count']),
+                str(metrics['retweet_count'])
+            )
+        
+        self.console.print(table)
+
+# Dependency for FastAPI endpoints
+def get_twitter_service(client: TwitterClient = Depends(get_twitter_client)):
+    return TwitterService(client=client)
+
+# FastAPI endpoints
+@app.get("/health")
+async def health_check():
+    """Health check endpoint."""
+    return {"status": "healthy"}
+
+@app.get("/api/me", response_model=UserInfo)
+async def get_me(service: TwitterService = Depends(get_twitter_service)):
+    """Get authenticated user info."""
+    try:
+        me = service.client.get_me()
+        return UserInfo(
+            username=me.data.username,
+            id=me.data.id,
+            name=getattr(me.data, 'name', None)
+        )
+    except tweepy.TweepyException as e:
+        raise HTTPException(status_code=500, detail=str(e))
+
+@app.get("/api/likes", response_model=List[Tweet])
+async def get_likes(
+    count: int = 10,
+    service: TwitterService = Depends(get_twitter_service)
+):
+    """Get recent likes for authenticated user."""
+    return service.get_recent_likes(count)
+
+# Add new endpoints for zero engagement tweets and replies
+@app.get("/api/tweets/zero-engagement", response_model=List[Tweet])
+async def get_zero_engagement_tweets(
+    service: TwitterService = Depends(get_twitter_service)
+):
+    """Get tweets with zero engagement."""
+    try:
+        # Get user ID for the authenticated user
+        me = service.client.get_me()
+        user_id = me.data.id
+        
+        # Get user's tweets
+        tweets = service.client.get_users_tweets(
+            user_id,
+            max_results=100,  # Adjust as needed
+            tweet_fields=['created_at', 'public_metrics', 'text', 'in_reply_to_user_id'],
+            exclude=['retweets', 'replies']  # Only get original tweets
+        )
+        
+        if not tweets.data:
+            return []
+        
+        # Filter for zero engagement tweets
+        zero_engagement_tweets = []
+        for tweet in tweets.data:
+            metrics = tweet.public_metrics
+            # Consider a tweet to have zero engagement if it has no likes, retweets, or replies
+            if metrics['like_count'] == 0 and metrics['retweet_count'] == 0 and metrics['reply_count'] == 0:
+                zero_engagement_tweets.append({
+                    'id': str(tweet.id),
+                    'text': tweet.text,
+                    'created_at': tweet.created_at.isoformat(),
+                    'engagement_count': 0
+                })
+        
+        return zero_engagement_tweets
+        
+    except tweepy.TweepyException as e:
+        logger.error(f"Error fetching zero engagement tweets: {str(e)}")
+        raise HTTPException(status_code=500, detail=str(e))
+
+@app.get("/api/replies/zero-engagement", response_model=List[Tweet])
+async def get_zero_engagement_replies(
+    service: TwitterService = Depends(get_twitter_service)
+):
+    """Get replies with zero engagement."""
+    try:
+        # Get user ID for the authenticated user
+        me = service.client.get_me()
+        user_id = me.data.id
+        
+        # Get user's replies
+        replies = service.client.get_users_tweets(
+            user_id,
+            max_results=100,  # Adjust as needed
+            tweet_fields=['created_at', 'public_metrics', 'text', 'in_reply_to_user_id', 'referenced_tweets'],
+            exclude=['retweets']  # Include replies but exclude retweets
+        )
+        
+        if not replies.data:
+            return []
+        
+        # Filter for zero engagement replies
+        zero_engagement_replies = []
+        for reply in replies.data:
+            # Skip if not a reply
+            if not reply.in_reply_to_user_id:
+                continue
                 
-    #         }
-        # if int(fav_count) > 0:
-        #     print(f'fav count: {t['tweet']['favorite_count']}')
-        #     print(generate_url_from_id(tw_id))
-        # if int(rt_count) > 0:
-        #     print(f'rt count: {t['tweet']['retweet_count']}')
-        #     print(generate_url_from_id(tw_id))
-
-    # display_db(conn)
-
-    terminate(conn)
+            metrics = reply.public_metrics
+            # Consider a reply to have zero engagement if it has no likes, retweets, or replies
+            if metrics['like_count'] == 0 and metrics['retweet_count'] == 0 and metrics['reply_count'] == 0:
+                # Get the tweet this is replying to
+                referenced_tweet = None
+                if reply.referenced_tweets:
+                    for ref in reply.referenced_tweets:
+                        if ref.type == 'replied_to':
+                            try:
+                                original_tweet = service.client.get_tweet(ref.id)
+                                referenced_tweet = original_tweet.data
+                            except tweepy.TweepyException:
+                                referenced_tweet = None
+                            break
+                
+                zero_engagement_replies.append({
+                    'id': str(reply.id),
+                    'text': reply.text,
+                    'created_at': reply.created_at.isoformat(),
+                    'engagement_count': 0,
+                    'in_reply_to': referenced_tweet.text if referenced_tweet else "Original tweet not found"
+                })
+        
+        return zero_engagement_replies
+        
+    except tweepy.TweepyException as e:
+        logger.error(f"Error fetching zero engagement replies: {str(e)}")
+        raise HTTPException(status_code=500, detail=str(e))
+
+@app.get("/api/test-auth", response_model=AuthStatus)
+async def test_authentication(
+    service: TwitterService = Depends(get_twitter_service)
+):
+    """Test Twitter API authentication and data fetching capabilities."""
+    try:
+        # Get rate limit info if any
+        rate_limit = service.client.rate_limit_info
+        
+        # If we're rate limited, return that status
+        if rate_limit and rate_limit.is_rate_limited:
+            return AuthStatus(
+                is_authenticated=True,  # We might still be authenticated
+                rate_limit=rate_limit,
+                error=f"Rate limited on {rate_limit.endpoint}. Reset in {rate_limit.wait_seconds} seconds."
+            )
+        
+        # Test authentication by getting user info
+        me = service.client.get_me()
+        username = me['data']['username']
+        
+        # Test data fetching by getting a single tweet
+        try:
+            tweets = service.client.get_users_tweets(
+                me['data']['id'],
+                max_results=1,
+                tweet_fields=['created_at', 'public_metrics', 'text']
+            )
+            
+            return AuthStatus(
+                is_authenticated=True,
+                username=username,
+                can_fetch_data=True,
+                test_tweet_count=len(tweets['data']) if tweets.get('data') else 0,
+                rate_limit=service.client.rate_limit_info
+            )
+        except tweepy.TooManyRequests as e:
+            service.client._handle_rate_limit(e)
+            return AuthStatus(
+                is_authenticated=True,
+                username=username,
+                rate_limit=service.client.rate_limit_info,
+                error=f"Rate limited while fetching tweets. Reset in {service.client.rate_limit_info.wait_seconds} seconds."
+            )
+        
+    except tweepy.Unauthorized as e:
+        logger.error(f"Authentication test failed: {str(e)}")
+        return AuthStatus(
+            is_authenticated=False,
+            error="Authentication failed. Please check your Twitter API credentials.",
+            can_fetch_data=False
+        )
+    except tweepy.Forbidden as e:
+        logger.error(f"Permission test failed: {str(e)}")
+        return AuthStatus(
+            is_authenticated=True,
+            username=username if 'username' in locals() else None,
+            error="API permissions issue. Please check your app's permissions in the Twitter Developer Portal.",
+            can_fetch_data=False
+        )
+    except tweepy.TweepyException as e:
+        logger.error(f"API test failed: {str(e)}")
+        return AuthStatus(
+            is_authenticated=True,
+            username=username if 'username' in locals() else None,
+            error=f"API error: {str(e)}",
+            can_fetch_data=False
+        )
 
+# CLI functionality
+def main():
+    """CLI entry point."""
+    parser = argparse.ArgumentParser(description='Twitter Tools CLI')
+    parser.add_argument(
+        '-n', '--number',
+        type=int,
+        default=10,
+        help='Number of recent likes to fetch (default: 10)'
+    )
+    args = parser.parse_args()
+    
+    try:
+        service = TwitterService()
+        likes = service.get_recent_likes(count=args.number)
+        service.display_likes(likes)
+    except Exception as e:
+        logger.error(f"Error: {str(e)}")
+        raise SystemExit(1)
 
 if __name__ == "__main__":
-    init()
-    main()
+    main() 
\ No newline at end of file
